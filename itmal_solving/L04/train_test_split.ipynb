{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2$^3$\n",
    "\n",
    "REVISIONS|\n",
    "---------|------------------------------------------------\n",
    "2018-1218|CEF, initial.                  \n",
    "2019-0131|CEF, spell checked and update. \n",
    "2019-0104|CEF, minor source text update. \n",
    "\n",
    "## Train-Test Split\n",
    "\n",
    "An essential method in ML is the split between training data and test data. The model will be trained on only a portion of the complete dataset, typically around 80%, and training will _NEVER_ see the test-set left out.\n",
    "\n",
    "So, _never_ train on test (or validation) data!\n",
    "\n",
    "Normally we just use the built-in methods for splitting, namely \n",
    "\n",
    "   ```sklearn.model_selection.train_test_split```, \n",
    "\n",
    "see documentation here\n",
    "\n",
    "   * https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "   \n",
    "but in this exercise you want to build a test-train split function yourself.\n",
    "\n",
    "OPTIONAL: More documentation on Train-Validation-Test split at \n",
    "  \n",
    "   * https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Housing data form ยง2 [HOML] \n",
    "\n",
    "We use the housing data from the book, this cell will set everything up for you..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \"..\"\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    #path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"IGNORING: Saving figure\", fig_id)\n",
    "    #if tight_layout:\n",
    "    #    plt.tight_layout()\n",
    "    #plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"../datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"../datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "    \n",
    "fetch_housing_data()\n",
    "\n",
    "import pandas as pd\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()\n",
    "\n",
    "#housing.head()\n",
    "print(\"housing.shape=\",housing.shape,\"\\n\")\n",
    "housing.info()\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "housing.hist(bins=50, figsize=(20,15))\n",
    "#save_fig(\"attribute_histogram_plots\")\n",
    "plt.show()\n",
    "\n",
    "# NOTE: ITMAL, convert Pandas dataframe to numpy array, i.e. matrix\n",
    "#       and use H later instead of housing\n",
    "H = housing.values\n",
    "print('H.shape=',H.shape,\", type(H)=\",type(H))\n",
    "\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our own train-test split function\n",
    "\n",
    "<img src=\"Figs/training_and_test_splits.png\" style=\"height:300px\">\n",
    "\n",
    "### Qa Create Your Own Split Function\n",
    "\n",
    "Starting from the split function [HOML,p49], getting inspiration from it (do not copy it directly)\n",
    "\n",
    "```python\n",
    "def my_split_train_test(data, test_size, shuffle=False):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_size)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "```\n",
    "create your own split function, that can do the data shuffling (as it is now) or do a simpler split without shuffling.\n",
    "\n",
    "Notice that it would be better to name the function ```my_split_train_test``` to avoid clashing problems later with the Scikit-learn function of the same name. The ```test_ratio``` parameter has also been renamed to ```test_size```. \n",
    "\n",
    "Also note that the split function in [HOML] operates on Pandas data frames, and this will give us a mixup problem later, when we pass the function numpy arrays (matrices).\n",
    "\n",
    "Test that your new split function returns the same number of train and test data no matter if shuffleling is on or off, using the test stub below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qa...define your my_split_train_test here\n",
    "\n",
    "def my_split_train_test(...\n",
    "\n",
    "\n",
    "\n",
    "# TEST VECTORS: use the housing panda dataframe or the H numpy object, your choice\n",
    "dat=housing\n",
    "#dat=H\n",
    "\n",
    "def TestSize(train_set, test_set):\n",
    "    # works only for 0.2 split\n",
    "    expected_n_train=16512\n",
    "    expected_n_test=4128\n",
    "    assert len(train_set)==expected_n_train, 'Oh, mismatch in expected train n'\n",
    "    assert len(test_set) ==expected_n_test,  'Oh, mismatch in expected test n'\n",
    "    print(len(train_set), \"train +\", len(test_set), \"test\",\"..OK\")\n",
    "\n",
    "train_set, test_set = my_split_train_test(dat, 0.2, shuffle=True)\n",
    "TestSize(train_set, test_set)\n",
    "\n",
    "train_set, test_set = my_split_train_test(dat, 0.2, shuffle=False)\n",
    "TestSize(train_set, test_set)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(dat, test_size=0.2, shuffle=True, random_state=42)\n",
    "TestSize(train_set, test_set)\n",
    "\n",
    "train_set, test_set = train_test_split(dat, test_size=0.2, shuffle=False)\n",
    "TestSize(train_set, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qb Why Shuffling\n",
    "\n",
    "Explain why disabling shuffling is a bad idea?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qc Test and Compare \n",
    "\n",
    "Compare your split function with the one from Scikit-learn, first using the simple X-y data set generated below and then using the housing data via the ```H``` numpy array variable.\n",
    "\n",
    "Splitting the dataset via your split function and the built-in split does not yield a logical true for the comparison\n",
    "\n",
    "```python\n",
    "(y_train == y_train_my).all().all()\n",
    "```\n",
    "\n",
    "Why is it so? Find the exact values in ```H[i,j]``` that are not equal and explain the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple data for Qc\n",
    "\n",
    "import numpy as np\n",
    "X, y = np.arange(10).reshape((5, 2)), np.array(list(range(5)))\n",
    "\n",
    "print(\"X=\",X)\n",
    "print(\"y=\",y)\n",
    "\n",
    "# TODO: Qc...\n",
    "\n",
    "\n",
    "\n",
    "# TEST VECTORS: notice that H is not splitted into X-y parts\n",
    "train, test = train_test_split(H, test_size=0.25, shuffle=False)\n",
    "print(\"build-in split: len(train)=\",len(train),\", len(test)=\", len(test))\n",
    "\n",
    "train_my, test_my = my_split_train_test(H, test_size=0.25, shuffle=False)\n",
    "print(\"my split:       len(train)=\",len(train_my),\", len(test)=\", len(test_my))\n",
    "\n",
    "assert train.shape==train_my.shape\n",
    "\n",
    "# Test for equality here...\n",
    "assert train.shape==train_my.shape\n",
    "equal_train=(train==train_my).all().all()\n",
    "equal_test =(test ==test_my).all().all()\n",
    "\n",
    "# TODO: why not equal?\n",
    "print(\"equal_train=\", equal_train, \", equal_test=\",equal_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qd The Cross-Validation [CV] Algorithm\n",
    "\n",
    "For very small data sets, it can be difficult to split the data into sufficiently large train and test/validation data. One popular method is to split all data in smaller chunks, typically called K-folds or CV (CrossValidation) folds, and then estimate the total validation error from this set of train-test partitioned data. \n",
    "\n",
    "In figure form the CV works like this\n",
    "\n",
    "<img src=\"Figs/cross_validation.png\" style=\"width:500px\">\n",
    "\n",
    "or a little more verbose (ignore the B and C part for now)\n",
    "\n",
    "<img src=\"Figs/kfold.png\" style=\"width:650px\">\n",
    "\n",
    "Explain in test, pseudocode or diagrams, what how a cross-validation split works in detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [OPTIONAL] Qe Extend your splitter\n",
    "\n",
    "Extend your splitter, such that it can handle both numpy arrays and Panda data frames in both shuffle modes (you need to work on ```iloc``` in ```shuffle=True``` mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qe..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [OPTIONAL] Qf Implement a Cross-Validation Function\n",
    "\n",
    "From your description of a cross-validation algorithm in the question above, try to implement one. Compare it with the Scikit-learn function \n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "..\n",
    "scores = cross_val_score(.., cv=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qf..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
