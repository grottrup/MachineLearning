{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITMAL Exercise\n",
    "\n",
    "\n",
    "REVISIONS|\n",
    "---------|------------------------------------------------\n",
    "2018-1219| CEF, initial.                  \n",
    "2018-0207| CEF, updated.           \n",
    "2018-0207| CEF, rewritten accuracy paradox section.           \n",
    "\n",
    "## Performance Metrics\n",
    "\n",
    "There are a number of frequently uses metrics in ML, namely accuracy, precision, recall and the $F_1$ score. All are called _metrics_ (though they are not true norms, like ${\\cal L}_2$ or ${\\cal L}_1$ we saw last time).\n",
    "\n",
    "Maybe performance _score_ would be a better name than performance metric, at least for the accuracy, precision, recall we will be looking at---emphasising the conceptual distinction between the  _score-function_ and _cost(/loss/error/objective)-function_ (the later is typically a true distance/norm function).  \n",
    "\n",
    "\n",
    "You can find a lot of details on say precision and recall in Wikipedia\n",
    "\n",
    ">  https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "\n",
    "\n",
    "### Nomenclature\n",
    "\n",
    "NAME           |   SYMBOL   | ALIAS\n",
    "---------------| --------------------\n",
    "true positives | $TP$ |\n",
    "true negatives | $TN$ | \n",
    "false positives| $FP$ | type I error \n",
    "false negatives| $FN$ | type II error \n",
    "\n",
    "and $N = N_P + N_N$ being the total number of samples and the number of positive and negative samples\n",
    "respectively.\n",
    "\n",
    "### Precision\n",
    "\n",
    "$$\n",
    "\\def\\ba{\\begin{array}{lll}}\n",
    "\\def\\ea{\\end{array}}\n",
    "\\newcommand{\\rem}[1]{}\n",
    "\\newcommand{\\subtext}[1]{_{\\scriptsize{\\mbox{#1}}}}\n",
    "\\newcommand{\\st}[1]{\\subtext{#1}}\n",
    "\\ba\n",
    " p &= \\frac{TP}{TP + FP}\n",
    "\\ea\n",
    "$$\n",
    "\n",
    "### Recall or Sensitivity\n",
    "\n",
    "$$\n",
    "  \\ba\n",
    "    r &= \\frac{TP}{TP + FN}\\\\\n",
    "      &= \\frac{TP}{TP + FN}\\\\ \n",
    "      &= \\frac{TP}{N_P}\n",
    "  \\ea\n",
    "$$\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "$$\n",
    "  \\ba\n",
    "      a &= \\frac{TP + TN}{TP + TN + FP + FN}\\\\\n",
    "        &= \\frac{TP + TN}{N}\\\\\n",
    "        &= \\frac{TP + TN}{N_P + N_N} \n",
    "  \\ea\n",
    "$$\n",
    "\n",
    "#### Accuracy Paradox\n",
    "\n",
    "A static constant model, say $p\\st{cancer}=0$ may have higher accuracy than a real model with predictive power. This is odd!\n",
    "\n",
    "Asymmetric weight could also be associated with the false positive and false negative predictions, yielding either FP of FN much more expensive than the other. Say, it is more expensive not to treat a person with cancer, than treating a person without cancer. \n",
    "\n",
    "### F-score\n",
    "\n",
    "General $\\beta$-harmonic mean of the precision and recall \n",
    "$$\n",
    "    F_\\beta = (1+\\beta^2) \\frac{2pr}{\\beta^2 p+r}\\\\\n",
    "$$ \n",
    "that for say $\\beta=2$ or $\\beta=0.5$ shifts or skews the emphasis on the two variables in the equation. Normally only the $\\beta=1$ harmonic mean is used\n",
    "\n",
    "$$\n",
    "  \\ba\n",
    "    F_1     &= \\frac{2pr}{p+r}\\\\\n",
    "            &=\\frac{2}{1/p + 1/r}\n",
    "  \\ea\n",
    "$$\n",
    "with $F$ typically being synonymous with $F_1$. \n",
    "\n",
    "If needed, find more info on Wikipedia\n",
    "\n",
    "> https://en.wikipedia.org/wiki/F1_score\n",
    "\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "For statistical classification, the confusion matrix or error matrix (or\n",
    "matching matrix in unsupervised learning) is for a two-class problem given by\n",
    "the $2\\times2$ matrix with dimensions 'actual' and 'predicted'\n",
    "\n",
    "$$   \n",
    "{\\bf M}\\st{confusion} = \n",
    "\\begin{array}{l|ll}\n",
    "                           & \\mbox{actual true} & \\mbox{actual false} \\\\ \\hline\n",
    "    \\mbox{predicted true}  & TP & FP \\\\     \n",
    "    \\mbox{predicted false} & FN & TN \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The diagonal, in the square matrix, represent predicted values being the same\n",
    "as the actual values, off-diagonal elements represent erroneous prediction.\n",
    "\n",
    "For N-class classification the matrix gives a matrix with $N$ actual\n",
    "classes and $N$ predicted classes\n",
    "\n",
    "$$\n",
    "{\\bf M}\\st{confusion} =\n",
    "  \\left[\n",
    "  \\begin{array}{llll}\n",
    "       c_{11} & c_{12} & \\cdots & c_{1n} \\\\ \n",
    "       c_{21} & c_{22} & \\cdots & c_{2n} \\\\\n",
    "       \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "       c_{n1} & c_{n2} & \\cdots & c_{nn} \\\\ \n",
    "  \\end{array}\n",
    "  \\right]\n",
    "$$\n",
    "with say element $c_{21}$ being the number of actual classes '1' being predicted (erroneously) as class '2'.\n",
    "\n",
    "### Nomenclature for the Confusion Matrix\n",
    "\n",
    "The naming of the elements in the confusion matrix can be rather exotic, like _false omission rate_ (see the figure below), but we won't get to such detail here...let us stick with TP, TN, FP, FN and $F_1$!\n",
    "\n",
    "<img src=\"Figs/performance_metrics.png\" style=\"width:900px\">\n",
    "\n",
    "If you need more info on the confusion matrix:\n",
    "\n",
    ">  https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "\n",
    "#### Qa Implement the Accuracy function and test it on the MNIST data.\n",
    "\n",
    "Implement a general accuracy function `MyAccuracy`, that takes `y_pred` and `y_true` as input parameters.\n",
    "\n",
    "Reuse your MNIST data loader and test the `MyAccuracy` function  both on your dummy classifier and on the Stochastic Gradient Descent classifier (with setup parameters as in [HOLM])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jazzbear\\Documents\\GitRepos\\MachineLearning\\itmal_solving\n",
      "Fetched raw MNIST\n"
     ]
    }
   ],
   "source": [
    "% cd ..\n",
    "from libitmal import utils, dataloaders as dl\n",
    "\n",
    "mnist = dl.GetMNISTRaw()\n",
    "X, y = dl.MNIST_GetDataSet(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper-method for preparing the data set, splitting it into a training part and test part.\n",
    "# This is to reduce clutter in the code.\n",
    "def PrepForTraining():\n",
    "    # 10000 for test, 60000 for train\n",
    "    X_train, y_train = X[:60000], y[:60000]\n",
    "    X_test, y_test =  X[60000:], y[60000:]\n",
    "    \n",
    "    shuffle_index = np.random.permutation(60000)\n",
    "    X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\n",
    "    \n",
    "    y_train_5 = (y_train == 5)\n",
    "    y_test_5  = (y_test == 5)\n",
    "    \n",
    "    return y_train_5, y_test_5, X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD confusion matrix: \n",
      "[[8923  185]\n",
      " [ 271  621]]\n",
      "TN=8923, FP=185, FN=271, TP=621\n",
      "\n",
      "my accuracy= 0.9544\n",
      "scikit-learn a= 0.9544\n",
      "\n",
      "And now for DummyClassifier comparrison.\n",
      "\n",
      "Dummy confusion matrix: \n",
      "[[9108    0]\n",
      " [ 892    0]]\n",
      "TN=9108, FP=0, FN=892, TP=0\n",
      "\n",
      "my accuracy= 0.9108\n",
      "scikit-learn a= 0.9108\n"
     ]
    }
   ],
   "source": [
    "# TODO: Qa...\n",
    "# %cd ..\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from libitmal import dumdum\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Prep the train and test data\n",
    "y_train_5, y_test_5, X_train, y_train, X_test, y_test = PrepForTraining()\n",
    "\n",
    "# Instatiate a new SGD classifier and train it on the train set.\n",
    "sgd_clf = SGDClassifier(max_iter=1000, tol=np.infty, random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "\n",
    "dumdum_clf = dumdum.DummyClassifier()\n",
    "dumdum_clf.fit(X_train, y_train_5)\n",
    "\n",
    "# Get our y_pred from SGD Classifier\n",
    "y_test_pred_SGD = cross_val_predict(sgd_clf, X_test, y_test_5, cv=3)\n",
    "y_test_pred_DumDum = cross_val_predict(dumdum_clf, X_test, y_test_5, cv=3)\n",
    "\n",
    "def GetConfMatrixParams(name, y_true, y_pred):\n",
    "    # Confusion matrix shows:\n",
    "    # True Negative     False Positive\n",
    "    # False Negative    True Positive\n",
    "    print(f'{name} confusion matrix: ')\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    print(conf_matrix)   \n",
    "    TN = conf_matrix[0,0]\n",
    "    FP = conf_matrix[0,1]\n",
    "    FN = conf_matrix[1,0]\n",
    "    TP = conf_matrix[1,1]\n",
    "    # Retun a tupple with the Confusion parameters.\n",
    "    return TN, FP, FN, TP\n",
    "\n",
    "\n",
    "# Another approach to do this without using a confusion matrix given to us.\n",
    "# To help setting up definition of classification context:\n",
    "def GetConfusionParams(y_pred, y_true):    \n",
    "    TN, FP, FN, TP = 0, 0, 0, 0 #instantiate the variables as intergers.\n",
    "    # We iterrate through each of the predicted values,\n",
    "    # and with a AND-Gate approach we can sort the \n",
    "    for i in range (0, len(y_pred)):\n",
    "        # If y_pred and y_true both evalute the index as TRUE, we have a TP.\n",
    "        if y_pred[i] == True == y_true[i]:\n",
    "            TP +=1\n",
    "        # If the index is not indeed y_true==true we have a FP.\n",
    "        elif y_pred[i] == True != y_true[i]:\n",
    "            FP += 1\n",
    "        # if we have a predicted false but an actual true, its a FN.\n",
    "        elif y_pred[i] == False != y_true[i]:\n",
    "            FN += 1\n",
    "        # Last of course if we have TN when both evalutate false.\n",
    "        elif y_pred[i] == False == y_true[i]:\n",
    "            TN +=1\n",
    "    return TN, FP, FN, TP # Retun a tupple with the Confusion parameters.\n",
    "        \n",
    "def MyAccuracy(name, y_true, y_pred):\n",
    "#     TP, FP, FN, TN = GetConfusionParams(y_pred, y_true)\n",
    "    TN, FP, FN, TP = GetConfMatrixParams(name, y_true, y_pred)\n",
    "    print(f'TN={TN}, FP={FP}, FN={FN}, TP={TP}')\n",
    "    # per the formula on https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "    acc = (TP + TN) / (TP + FP + FN + TN)\n",
    "    return acc\n",
    "    \n",
    "# TEST FUNCTION: compare with Scikit-learn accuracy_score\n",
    "def TestAccuracy(name, y_true, y_pred):\n",
    "    a0=MyAccuracy(name, y_true, y_pred)\n",
    "    a1=accuracy_score(y_true, y_pred)\n",
    "    print(\"\\nmy accuracy=\",a0)\n",
    "    print(\"scikit-learn a=\",a1)\n",
    "    utils.InRange(a0,a1)\n",
    "\n",
    "# y_test_5 is our y_true, as defined earlier by: y_test_5 = (y_test = 5)\n",
    "TestAccuracy(\"SGD\", y_test_5, y_test_pred_SGD)\n",
    "print(\"\\nAnd now for DummyClassifier comparrison.\\n\")\n",
    "TestAccuracy(\"Dummy\", y_test_5, y_test_pred_DumDum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qb Implement Precision, Recall and $F_1$-score and test it on the MNIST data.\n",
    "\n",
    "Now, implement the `MyPrecision`, `MyRecall` and `MyF1Score` functions, again taking MNIST as input, using the SGD and the Dummy classifiers and make some test vectors to compare to the functions found in Scikit-learn..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "my precision= 0.7704714640198511\n",
      "scikit-learn precision= 0.7704714640198511\n",
      "\n",
      "my recall= 0.6961883408071748\n",
      "scikit-learn recall= 0.6961883408071748\n",
      "\n",
      "my F1= 0.7314487632508835\n",
      "scikit-learn f1= 0.7314487632508835\n",
      "\n",
      "The confusion matrix and the parameters:\n",
      "[[8923  185]\n",
      " [ 271  621]]\n",
      "TN=8923, FP=185, FN=271, TP=621\n",
      "\n",
      "Now for the whole thing again with dummy classifier:\n",
      "\n",
      "\n",
      "my precision= nan\n",
      "scikit-learn precision= 0.0\n",
      "\n",
      "my recall= 0.0\n",
      "scikit-learn recall= 0.0\n",
      "\n",
      "my F1= nan\n",
      "scikit-learn f1= 0.0\n",
      "\n",
      "The confusion matrix and the parameters, for dummy:\n",
      "[[9108    0]\n",
      " [ 892    0]]\n",
      "TN=9108, FP=0, FN=892, TP=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Qb..\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Again the formulas are based on those found at: https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "\n",
    "# The same method as earlier but no longer takes a named parameter.\n",
    "# Not needed, as we just want the params back and keep the output short.\n",
    "def GetConfParams(y_true, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred) \n",
    "    TN = conf_matrix[0,0]\n",
    "    FP = conf_matrix[0,1]\n",
    "    FN = conf_matrix[1,0]\n",
    "    TP = conf_matrix[1,1]\n",
    "    # Retun a tupple with the Confusion parameters.\n",
    "    return TN, FP, FN, TP\n",
    "\n",
    "\n",
    "def MyPrecision(y_true, y_pred):\n",
    "    TN, FP, FN, TP = GetConfParams(y_true, y_pred)\n",
    "#     print(TN, FP, FN, TP)    \n",
    "    precision = TP / (TP + FP)\n",
    "    return precision\n",
    "\n",
    "def MyRecall(y_true, y_pred):\n",
    "    TN, FP, FN, TP = GetConfParams(y_true, y_pred)\n",
    "#     print(TN, FP, FN, TP)  \n",
    "    recall = TP / (TP + FN)\n",
    "    return recall\n",
    "    \n",
    "def MyF1Score(y_true, y_pred):\n",
    "    TN, FP, FN, TP = GetConfParams(y_true, y_pred)\n",
    "#     print(TN, FP, FN, TP)  \n",
    "    recall = MyRecall(y_true, y_pred)\n",
    "    precision = MyPrecision(y_true, y_pred)\n",
    "    \n",
    "    # Finding F1_score: https://en.wikipedia.org/wiki/F1_score\n",
    "#     f1_score = 2 / (recall**-1 + precision**-1)\n",
    "    f1_score = 2 * ((precision*recall) / (precision+recall))\n",
    "    return f1_score\n",
    "\n",
    "\n",
    "def TestPrecision(y_true, y_pred):\n",
    "    p0 = MyPrecision(y_true, y_pred)\n",
    "    p1 = precision_score(y_true, y_pred)\n",
    "    print(\"\\nmy precision=\",p0)\n",
    "    print(\"scikit-learn precision=\",p1)\n",
    "    utils.InRange(p0,p1)\n",
    "    \n",
    "TestPrecision(y_test_5, y_test_pred_SGD)\n",
    "\n",
    "def TestRecall(y_true, y_pred):\n",
    "    r0 = MyRecall(y_true, y_pred)\n",
    "    r1 = recall_score(y_true, y_pred)\n",
    "    print(\"\\nmy recall=\",r0)\n",
    "    print(\"scikit-learn recall=\",r1)\n",
    "    utils.InRange(r0,r1)\n",
    "    \n",
    "TestRecall(y_test_5, y_test_pred_SGD)\n",
    "\n",
    "\n",
    "def TestF1Score(y_true, y_pred):\n",
    "    f1_0 = MyF1Score(y_true, y_pred)\n",
    "    f1_1 = f1_score(y_true, y_pred)\n",
    "    print(\"\\nmy F1=\",f1_0)\n",
    "    print(\"scikit-learn f1=\",f1_1)\n",
    "    utils.InRange(f1_0, f1_1)\n",
    "    \n",
    "TestF1Score(y_test_5, y_test_pred_SGD)\n",
    "\n",
    "print(\"\\nThe confusion matrix and the parameters:\")\n",
    "print(confusion_matrix(y_test_5, y_test_pred_SGD))\n",
    "TN, FP, FN, TP = GetConfParams(y_test_5, y_test_pred_SGD)\n",
    "print(f'TN={TN}, FP={FP}, FN={FN}, TP={TP}')\n",
    "\n",
    "\n",
    "# We will se that both sckikit-learn and our \"scoring\" methods will return 0 or nan,\n",
    "# which makes perfect sense as we have no FN, and FP, and this \n",
    "print(\"\\nNow for the whole thing again with dummy classifier:\\n\")\n",
    "TestPrecision(y_test_5, y_test_pred_DumDum)\n",
    "TestRecall(y_test_5, y_test_pred_DumDum)\n",
    "TestF1Score(y_test_5, y_test_pred_DumDum)\n",
    "\n",
    "print(\"\\nThe confusion matrix and the parameters, for dummy:\")\n",
    "print(confusion_matrix(y_test_5, y_test_pred_DumDum))\n",
    "TN, FP, FN, TP = GetConfParams(y_test_5, y_test_pred_DumDum)\n",
    "print(f'TN={TN}, FP={FP}, FN={FN}, TP={TP}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qc The Confusion Matrix\n",
    "\n",
    "Revisit your solution to Qb in the `dummy_classifier.ipynb`. Did you manage to print the confusion matrix for both the Dummy and the SGD classifier?\n",
    "\n",
    "I got the two confusion matrices\n",
    "\n",
    "```\n",
    "M_dummy=[[18166     0]\n",
    "        [ 1834     0]]\n",
    "   \n",
    "M_SDG=[[17618   548]\n",
    "      [  267  1567]]\n",
    "\n",
    "```\n",
    "your data may look similar (but not 100% equal). See if you can print the confusion matrix (some test code below for inspiration).\n",
    "\n",
    "How are the Scikit-learn confusion matrix organized, where are the TP, FP, FN and TN located in the matrix indices, and what happens if you mess up the parameters calling\n",
    "\n",
    "```python\n",
    "confusion_matrix(y_train_pred, y_train_5)\n",
    "```\n",
    "\n",
    "instead of \n",
    "```python\n",
    "confusion_matrix(y_train_5, y_train_pred)\n",
    "```\n",
    "\n",
    "Finally, compare the real and symmetric auto-covariance matrix, $\\Sigma$, with the real but non-symmetric confusion matrix, $\\mathbf{M}$. What does the diagonal represent in the covar- and confusion matrix respectively, and why is the covar- symmetric, but the confusion not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "conf_mx_sgd= [[8923  185]\n",
      "               [ 271  621]]\n",
      "\n",
      "conf_mx_dumdum= [[9108    0]\n",
      "                  [ 892    0]]\n",
      "\n",
      "dumdum_switcharoo= [[9108  892]\n",
      "                     [   0    0]]\n",
      "\n",
      "sgd_switcharoo= [[8923  271]\n",
      "                  [ 185  621]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Qc \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from libitmal import dumdum\n",
    "\n",
    "\n",
    "# TEST CODE: some demo code to produce a 'test' confusion matrix using the SGD model \n",
    "\n",
    "# Using the the predictions we just got above we just make a new confusion matrix for sgd.\n",
    "conf_mx_sgd = confusion_matrix(y_test_5, y_test_pred_SGD)\n",
    "utils.PrintMatrix(conf_mx_sgd,\"\\nconf_mx_sgd= \")\n",
    "\n",
    "# Same for the dummy classifier\n",
    "conf_mx_dumdum = confusion_matrix(y_test_5, y_test_pred_DumDum)\n",
    "utils.PrintMatrix(conf_mx_dumdum,\"\\nconf_mx_dumdum= \")\n",
    "\n",
    "'''\n",
    "The confusion matrix switches the places of the false positives,\n",
    "and the false negatives around as shown in dumdum_switcharoo, and also in the sgd_switcharoo. \n",
    "Bassicaly the oututs are the transpose of the previous.\n",
    "'''\n",
    "dumdum_switcharoo = confusion_matrix(y_test_pred_DumDum, y_test_5)\n",
    "utils.PrintMatrix(dumdum_switcharoo,\"\\ndumdum_switcharoo= \")\n",
    "\n",
    "sgd_switcharoo = confusion_matrix(y_test_pred_SGD, y_test_5)\n",
    "utils.PrintMatrix(sgd_switcharoo, \"\\nsgd_switcharoo= \")\n",
    "\n",
    "\n",
    "'''\n",
    "We can see a symatri in the SGD matrix which is to be expected.\n",
    "The rows are represent the \"actual classes\", and columns the \"predicted classes\".\n",
    "Because of this its is 2 ways representing the same difference, i.e how 2 different values,\n",
    "\"vary\" together aka \"covariance\". This is depicted more visually later in the heatmap.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qd A Confusion Matrix Heat-map\n",
    "\n",
    "Generate a _heat map_ image for the confusion matrices, `M_dummy` and `M_SGD` respectively, getting inspiration from [HOML], pp96-97.\n",
    "\n",
    "This heat map could be an important guide for you when analysing multiclass data in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of SGDClassifier after scaling:\n",
      "[0.9090182  0.90854543 0.91118668]\n",
      "\n",
      "And the confusion matrix for the whole train set:\n",
      "[[5737    2   21   12   13   45   45    8   36    4]\n",
      " [   2 6462   48   24    6   46    6   15  123   10]\n",
      " [  51   39 5341   98   79   27   90   54  164   15]\n",
      " [  49   39  139 5321    1  245   32   54  149  102]\n",
      " [  24   28   40    9 5348   11   52   31   89  210]\n",
      " [  71   38   34  179   71 4628   95   28  192   85]\n",
      " [  33   23   45    2   41  101 5618    7   48    0]\n",
      " [  26   19   71   27   56   10    7 5810   14  225]\n",
      " [  53  153   73  152   15  163   53   22 5027  140]\n",
      " [  47   34   25   86  157   35    3  194   85 5283]]\n",
      "\n",
      "Then for DummyClassifier scaling and confusion matrix, of train set.\n",
      "The accuracy of DummyClassifier after scaling:\n",
      "[0.09873025 0.09870494 0.09871481]\n",
      "\n",
      "And the confusion matrix for the whole train set:\n",
      "[[5923    0    0    0    0    0    0    0    0    0]\n",
      " [6742    0    0    0    0    0    0    0    0    0]\n",
      " [5958    0    0    0    0    0    0    0    0    0]\n",
      " [6131    0    0    0    0    0    0    0    0    0]\n",
      " [5842    0    0    0    0    0    0    0    0    0]\n",
      " [5421    0    0    0    0    0    0    0    0    0]\n",
      " [5918    0    0    0    0    0    0    0    0    0]\n",
      " [6265    0    0    0    0    0    0    0    0    0]\n",
      " [5851    0    0    0    0    0    0    0    0    0]\n",
      " [5949    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Qd\n",
    "from matplotlib import pyplot as plt, cm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "'''\n",
    "As explained in chapter 2, p65 most algorithms perform better, with feature scaling.\n",
    "This is why in the steps on chapter 3, p96-97, we use the StandardScaler to perform standardization.\n",
    "'''\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "print(\"The accuracy of SGDClassifier after scaling:\")\n",
    "print(cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\"))\n",
    "\n",
    "y_train_pred_sgd = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
    "conf_mx_sgd = confusion_matrix(y_train, y_train_pred_sgd)\n",
    "print(\"\\nAnd the confusion matrix for the whole train set:\")\n",
    "print(conf_mx_sgd)\n",
    "\n",
    "# And the for the dummy classifier we do the same.\n",
    "print(f'\\nThen for DummyClassifier scaling and confusion matrix, of train set.')\n",
    "print(\"The accuracy of DummyClassifier after scaling:\")\n",
    "print(cross_val_score(dumdum_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\"))\n",
    "\n",
    "y_train_pred_dumdum = cross_val_predict(dumdum_clf, X_train_scaled, y_train, cv=3)\n",
    "conf_mx_dumdum = confusion_matrix(y_train, y_train_pred_dumdum)\n",
    "print(\"\\nAnd the confusion matrix for the whole train set:\")\n",
    "print(conf_mx_dumdum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAACwlJREFUeJzt3c+L3PUdx/HXK7tZ88OKhvaSbGgMFFtRa2QpaiAH46GtQS89GFCol1xajSKI9uI/IKKHIiyxXgx6iDkUFWtBPRQkdLMR17hWRG2MiZgSqiKY7LjvHmYENenOd3He893J+/kAIbt+8+HtOM/9zsx+5zOOCAGoZVXbAwAYPsIHCiJ8oCDCBwoifKAgwgcKai1827+2/S/b79l+sK05mrK92fartudtH7W9t+2ZmrA9ZvuI7efbnqUJ25faPmD7nd5tfUPbM/Vj+77efeIt28/YXtP2TP20Er7tMUl/lvQbSVdK2m37yjZmWYaOpPsj4heSrpf0hxGYWZL2Sppve4hleFzSSxHxc0m/1Aqf3fYmSfdImoqIqySNSbq93an6a+uM/ytJ70XE+xFxVtKzkm5raZZGIuJkRMz2/vyFunfITe1OtTTbk5JukbSv7VmasH2JpB2SnpSkiDgbEf9td6pGxiWttT0uaZ2kEy3P01db4W+S9NG3vj6uFR7Rt9neImmbpEPtTtLXY5IekLTY9iANbZV0StJTvacn+2yvb3uopUTEx5IekXRM0klJn0XEy+1O1V9b4fs83xuJa4dtXyzpOUn3RsTnbc/z/9jeJenTiDjc9izLMC7pOklPRMQ2SV9KWtGv/9i+TN1Hq5dL2ihpve072p2qv7bCPy5p87e+ntQIPDyyvVrd6PdHxMG25+lju6RbbX+o7lOpm2w/3e5IfR2XdDwivnkkdUDdHwQr2c2SPoiIUxGxIOmgpBtbnqmvtsL/p6Sf2b7c9oS6L4b8taVZGrFtdZ97zkfEo23P009EPBQRkxGxRd3b95WIWNFnooj4RNJHtq/ofWunpLdbHKmJY5Kut72udx/ZqRX+gqTUfWg1dBHRsf1HSX9T91XQv0TE0TZmWYbtku6UNGf7jd73/hQRL7Y404Xobkn7eyeE9yXd1fI8S4qIQ7YPSJpV9zc/RyRNtztVf+ZtuUA9XLkHFET4QEGEDxRE+EBBhA8U1Hr4tve0PcNyjNq8EjMPw6jN23r4kkbqBtPozSsx8zCM1LwrIXwAQ5ZyAc+GDRticnKy0bGnT5/Whg0bGh07Nzf3Q8YCSoiI870J7jtSLtmdnJzUiy8O/krWzZs39z8IP1j3kvPRknUFauZt0eZVszzUBwoifKAgwgcKInygIMIHCmoU/qjtgQ9gaX3DH9E98AEsockZf+T2wAewtCbhj/Qe+ADO1ST8Rnvg295je8b2zOnTp3/4ZADSNAm/0R74ETEdEVMRMdX02nsA7WgS/sjtgQ9gaX3fpDOie+ADWEKjd+f1PjSCD44ALhBcuQcURPhAQYQPFET4QEGEDxSUstmm7ZTNxDL3KFu1Kudn4Ch+GnHWPnOjeFuMj+d9knyn00lZt8lmm5zxgYIIHyiI8IGCCB8oiPCBgggfKIjwgYIIHyiI8IGCCB8oiPCBgggfKIjwgYIIHyiI8IGCCB8oiPCBgggfKIjwgYIIHyiI8IGCCB8oKG3v4IztqrO2wJakN998M2Xda6+9NmXdTIuLiynrjo2Npawr5W3dnXmfa9OF+V8FYEmEDxRE+EBBhA8URPhAQYQPFET4QEF9w7e92fartudtH7W9dxiDAcjT5AKejqT7I2LW9o8kHbb994h4O3k2AEn6nvEj4mREzPb+/IWkeUmbsgcDkGdZz/Ftb5G0TdKhjGEADEfja/VtXyzpOUn3RsTn5/n3eyTtGeBsAJI0Ct/2anWj3x8RB893TERMS5ruHZ/zjgkAA9HkVX1LelLSfEQ8mj8SgGxNnuNvl3SnpJtsv9H757fJcwFI1PehfkT8Q5KHMAuAIeHKPaAgwgcKInygIMIHCiJ8oCBn7E5qO7q//h8d4+M5Gw4fPnw4ZV1Juuaaa1LWXbt2bcq6X331Vcq6kpR1fxu1nYE7nY4iou+NwRkfKIjwgYIIHyiI8IGCCB8oiPCBgggfKIjwgYIIHyiI8IGCCB8oiPCBgggfKIjwgYIIHyiI8IGCCB8oiPCBgggfKIjwgYIIHyiI8IGC0rbXHviiyttCOVPG7fuNubm5lHWvvvrqlHVXrco7z2Tdzpkzr169euBrnjlzRouLi2yvDeBchA8URPhAQYQPFET4QEGEDxRE+EBBjcO3PWb7iO3nMwcCkG85Z/y9kuazBgEwPI3Ctz0p6RZJ+3LHATAMTc/4j0l6QNJi4iwAhqRv+LZ3Sfo0Ig73OW6P7RnbMwObDkCKJmf87ZJutf2hpGcl3WT76e8fFBHTETEVEVMDnhHAgPUNPyIeiojJiNgi6XZJr0TEHemTAUjD7/GBgsaXc3BEvCbptZRJAAwNZ3ygIMIHCiJ8oCDCBwoifKCgtF12M3YnzdyxNsvExETa2gsLCynrvvDCCynr7tq1K2VdSVpczLmaPPP/X6fTGfiaX3/9tSKCXXYBnIvwgYIIHyiI8IGCCB8oiPCBgggfKIjwgYIIHyiI8IGCCB8oiPCBgggfKIjwgYIIHyiI8IGCCB8oiPCBgggfKIjwgYIIHygobZddu+9Gn8uWuctuxrzSaM48NjaWsu67776bsq4kbd26NWXdrNtYyrtvsMsugPMifKAgwgcKInygIMIHCiJ8oCDCBwpqFL7tS20fsP2O7XnbN2QPBiDPeMPjHpf0UkT8zvaEpHWJMwFI1jd825dI2iHp95IUEWclnc0dC0CmJg/1t0o6Jekp20ds77O9PnkuAImahD8u6TpJT0TENklfSnrw+wfZ3mN7xvbMgGcEMGBNwj8u6XhEHOp9fUDdHwTfERHTETEVEVODHBDA4PUNPyI+kfSR7St639op6e3UqQCkavqq/t2S9vde0X9f0l15IwHI1ij8iHhDEg/hgQsEV+4BBRE+UBDhAwURPlAQ4QMFET5QENtr96xalfMzcBS3115cXExZN9OJEydS1t24cWPKupK0Zs2aga955swZLS4usr02gHMRPlAQ4QMFET5QEOEDBRE+UBDhAwURPlAQ4QMFET5QEOEDBRE+UBDhAwURPlAQ4QMFET5QEOEDBRE+UBDhAwURPlAQ4QMFpe2ym7Fr7fh40w/3Xb5Op5OybubMZ8+eTVl3YmIiZd2s21jK2xn49ddfT1lXknbs2DHwNTudDrvsAjg/wgcKInygIMIHCiJ8oCDCBwoifKCgRuHbvs/2Udtv2X7G9uA/5hPA0PQN3/YmSfdImoqIqySNSbo9ezAAeZo+1B+XtNb2uKR1knI+jBzAUPQNPyI+lvSIpGOSTkr6LCJezh4MQJ4mD/Uvk3SbpMslbZS03vYd5zluj+0Z2zODHxPAIDV5qH+zpA8i4lRELEg6KOnG7x8UEdMRMRURU4MeEsBgNQn/mKTrba+zbUk7Jc3njgUgU5Pn+IckHZA0K2mu93emk+cCkKjRm8Uj4mFJDyfPAmBIuHIPKIjwgYIIHyiI8IGCCB8oiPCBgtK21+5e6zM6Mm4HSRobG0tZN3PthYWFlHWzbmNJuuiii1LWzdwSfHZ2duBr7t69W0ePHmV7bQDnInygIMIHCiJ8oCDCBwoifKAgwgcKInygIMIHCiJ8oCDCBwoifKAgwgcKInygIMIHCiJ8oCDCBwoifKAgwgcKInygIMIHCsraZfeUpH83PPzHkv4z8CHyjNq8EjMPw0qZ96cR8ZN+B6WEvxy2ZyJiqtUhlmHU5pWYeRhGbV4e6gMFET5Q0EoIf7rtAZZp1OaVmHkYRmre1p/jAxi+lXDGBzBkhA8URPhAQYQPFET4QEH/A+KqtmIKVY50AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(conf_mx_sgd, cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "# Like its explained in the book, we can see that the 5's are darker than the rest.\n",
    "# Which could mean it performs worse on 5's, or the fact that we know there is only a 10%\n",
    "# of the dataset that is 5's, which could be affecting the result and scoring here.\n",
    "\n",
    "# The diagonal for the dumdum confusion matrix\n",
    "plt.matshow(conf_mx_dumdum, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SGD confusion matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dummy confusion matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "To verify this, wwe divide each value in our confusion matrix above,\n",
    "by the number of images in the corresponding class. This way we can compare the error rates,\n",
    "instead of the absolute number of errors in each class.\n",
    "'''\n",
    "row_sums_sgd = conf_mx_sgd.sum(axis=1, keepdims=True)\n",
    "# By dividing each sum we get the norm.\n",
    "norm_conf_mx_sgd = conf_mx_sgd / row_sums_sgd\n",
    "\n",
    "# Then as to keep only the errors, we replace all the true values\n",
    "# in the diagolnal, with zeroes.\n",
    "np.fill_diagonal(norm_conf_mx_sgd, 0)\n",
    "plt.matshow(norm_conf_mx_sgd, cmap = plt.cm.gray)\n",
    "print(\"\\nSGD confusion matrix:\")\n",
    "plt.show()\n",
    "'''\n",
    "The rows are represent the \"actual classes\", and columns the \"predicted classes\".\n",
    "With this we can see from column 8 and 9, which are quite bright in colors, comparetivly.\n",
    "That alot of images are missclassified, as 8s or 9s. \n",
    "Furthermore this can also be seen by row 8 and 9, which shows us (by the brightness again),\n",
    "that 8 and 9 digtis often are confused as other digits.\n",
    "\n",
    "We can also see that row 1 is quite dark (with the exception of 8th column),\n",
    "which means for the most part it recognices 1's well and only sometimes,\n",
    "is confused by some 8 digits.\n",
    "'''\n",
    "\n",
    "#Doing the same for the dummy:\n",
    "row_sums_dumdum = conf_mx_dumdum.sum(axis=1, keepdims=True)\n",
    "# By dividing each sum we get the norm.\n",
    "norm_conf_mx_dumdum = conf_mx_dumdum / row_sums_dumdum\n",
    "\n",
    "# As we can see since it will just say no to everything.\n",
    "# But we can also see that 0 is apparently not classified correctly ever.\n",
    "np.fill_diagonal(norm_conf_mx_dumdum, 0)\n",
    "plt.matshow(norm_conf_mx_dumdum, cmap = plt.cm.gray)\n",
    "print(\"\\nDummy confusion matrix:\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qe Run a classifier on your data\n",
    "\n",
    "Finally, try to run a classifier on the data-set you selected previously, perhaps starting with the SGD.\n",
    "\n",
    "Is it possible to classify at all on your data, or do we need regression instead?\n",
    "\n",
    "Are you able to do supervised learning, or are there no obvious `y_true` data in your set at all?\n",
    "\n",
    "If your data is in the form, where you are able to do supervised-classification, could you produce a confusion matrix heatmap, then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qe...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
