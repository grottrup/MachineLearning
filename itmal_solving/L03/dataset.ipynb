{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITMAL Exercise\n",
    "\n",
    "REVISIONS|\n",
    "---------|------------------------------------------------\n",
    "2018-1219| CEF, initial.                  \n",
    "2018-0206| CEF, updated and spell checked. \n",
    "2018-0206| CEF, added Kaggle dataset exercise. \n",
    "\n",
    "## Vanilla Datasets\n",
    "\n",
    "There are a number of popular datasets out-there, that are used again and again for small scale testing in ML: most popular are Moon, MNIST, Iris and CIFAR(10/100). We will use the three first here. \n",
    "\n",
    "(More on ML datasets: https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research)\n",
    "\n",
    "### Moon\n",
    "\n",
    "<img src=\"Figs/moon.png\" style=\"width:400px\">\n",
    "\n",
    "#### Qa Data load function \n",
    "\n",
    "We begin with a 100% synthetic dataset called moon. It creates two interleaved half-moon like datasets, and is frequently used as an XOR-like problem set (especially in Deep Learning).  \n",
    "\n",
    "Create a `MOON_GetDataSet()` that generates moon data, based on Scikit-learn's `make_moon()` function.\n",
    "\n",
    "Extend the `MOON_GetDataSet()`function signature to include some of the parameters found in `make_moon()`, like 'n_sample'.\n",
    "\n",
    "Also create a `MOON_Plot()` function, that plots the data...good thing here is that the feature set is 2D and easy to handle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qa...\n",
    "\n",
    "# NOTE: some free help here regarding import clauses...\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "def MOON_GetDataSet(...\n",
    "    # TODO: your code here...\n",
    "\n",
    "def MOON_Plot(X, y):\n",
    "    # TODO: some simple plot commands, \n",
    "   \n",
    "                    \n",
    "                    \n",
    "# TEST CODE:\n",
    "X, y=MOON_GetDataSet(n_samples=200)\n",
    "print(\"X.shape=\",X.shape,\", y.shape=\",y.shape)\n",
    "MOON_Plot(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qb Try it with a  train-test split function\n",
    "\n",
    "Now, use a train-test split function from Scikit-learn, that is able to split a `(X, y)` dataset tuple into a train-set and a test-set. \n",
    "\n",
    "Plot the train and test data using your `MOON_Plot` function.\n",
    "\n",
    "Extend the plot function to add a plot title and x- and y-labels to the plot, say as default parameters\n",
    "\n",
    "```python \n",
    "def MOON_Plot(X, y, title=\"my title\", xlable=\"\", ylabel=\"\"):\n",
    "    # implementation here...\n",
    "```\n",
    "\n",
    "or similar. Use the titles \"train\" and \"test\" when plotting the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qb...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST\n",
    "\n",
    "MNIST is a set of 70000 handwritten digits. It is used intensively as a form of \"Hello World\" dataset and estimator intensively check in Machine Learning. \n",
    "\n",
    "<img src=\"Figs/mnist.png\" style=\"width:400px\">\n",
    "\n",
    "<!-- ![MNIST](https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/MnistExamples.png/220px-MnistExamples.png)-->\n",
    "\n",
    "\n",
    "https://en.wikipedia.org/wiki/MNIST_database\n",
    "\n",
    "#### Qc Data load function \n",
    "\n",
    "Now for the MNIST data set, creating an easy to use data-loader, `MNIST_GetDataSet()`.\n",
    "\n",
    "There are several ways of getting the MNIST dataset. You could base the data loader on the `fetch_mldata('MNIST original')` function or try to use the `keras.datasets.mnist.load_data()` function. \n",
    "\n",
    "The later function pre-splits into a train-test set, and to be compatible with the former, you must concatenate the train-test and return a plain `X, y` set. \n",
    "\n",
    "Also create a `MNIST_PlotDigit()`, that is able to plot a single digit from the dataset, and try to plot some of the digits in the dataset (set TEST CODE below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qc...\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from keras.datasets import mnist\n",
    "\n",
    "def MNIST_PlotDigit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    # TODO: add plot functionality for a single digit...\n",
    "\n",
    "def MNIST_GetDataSet():\n",
    "    # TODO: use mnist = fetch_mldata('MNIST original') or mnist.load_data(),\n",
    "    #       but return as a single X-y tuple \n",
    "    \n",
    "\n",
    "\n",
    "# TEST CODE:\n",
    "X, y = MNIST_GetDataSet()\n",
    "print(\"X.shape=\",X.shape, \", y.shape=\",y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=50000, shuffle=True)\n",
    "\n",
    "print(\"X_train.shape=\",X_train.shape,\", X_test.shape=\",X_test.shape)\n",
    "MNIST_PlotDigit(X_train[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris\n",
    "\n",
    "Finally, for the iris data set: a four-dimension data set for 150 iris flowers, original created by  biologist Ronald Fisher and published via a paper in 1936.\n",
    "\n",
    "<img src=\"Figs/iris.jpg\" style=\"width:400px\">\n",
    "\n",
    "<!-- https://en.wikipedia.org/wiki/File:Iris_versicolor_3.jpg -->\n",
    "<!-- ![biologist Ronald Fisher](https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/R._A._Fischer.jpg/200px-R._A._Fischer.jpg) -->\n",
    "\n",
    "https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
    "\n",
    "#### Qd Data load function \n",
    "\n",
    "Creating the iris data loader, `IRIS_GetDataSet()`, this time we use the iris loader located in `sklearn.datasets.load_iris()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qd..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qe Examine the data via scatter plots\n",
    "\n",
    "Now, as a data-scientist, it is always good to get some grasp on how your data looks like. For the iris data we now want to plot some of the features-against-some-of-the other-features to see how they separate in the given 2D-feature space.\n",
    "\n",
    "A scatter plot for all iris features against all other may look like\n",
    "\n",
    "<img src=\"Figs/Iris_dataset_scatterplot.svg.png\" style=\"width:400px\">\n",
    "\n",
    "Create a plot function that takes just two feature dimensions and plots them in a 2D plot, and plot all features against all others (resembling the \"Iris Data\" scatter plot just above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qe..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qf Add your function to the `libitmal` python module\n",
    "\n",
    "Add all your moon, MNIST and iris get and plot functions to the `libitmal` module. Call the file `dataloaders.py`, and test it in a ___new___ jupyter notebook (you need to reset the notebooks to be able to see if you are calling _cached_ version of the functions or the new ones, with similar names, in the lib module).\n",
    "\n",
    "You will use these data loaders later, when we want to train on small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qf..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Datasets\n",
    "\n",
    "OK, now you need to find a dataset of your own! \n",
    "\n",
    "Goto www.kaggle.com and find a suitable dataset, that you want to work with. We want a set somewhat larger that iris or nmist but it should not be too big. \n",
    "\n",
    "You need to create an account at Kaggle before you download.\n",
    "\n",
    "One example could be the beer consumption in Sao Paulo:\n",
    "\n",
    "> https://www.kaggle.com/dongeorge/beer-consumption-sao-paulo/version/2\n",
    "\n",
    "It is a 'small-data' set, download gives a 5Kb comma-separated file (CSV)...\n",
    "\n",
    "\n",
    "#### Qg Download a data set and do some data exploration of it\n",
    "\n",
    "You are now a Data Scientist, go an examine your data, perhaps creating some feature scatter plots, just like the ones we just made for iris...\n",
    "\n",
    "Are there `null`s or not-a-number data in your set? Do you have to filter these out before training?\n",
    "\n",
    "Try to train-test split the set, perhaps just on a small set of its feature depending on the size of your data (small/medium/large/big), and try out one or two Scikit-learn ML algorithms on it just to see if it is possible.\n",
    "\n",
    "(We return to the data set and training later...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
